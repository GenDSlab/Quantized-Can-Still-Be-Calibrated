{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cus_datasets_funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Data Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TriviaQA Usage\n",
    "# tqa_dict = initialize_data_dict(\n",
    "#     process_triviaqa_sample, \"trivia_qa\", \"rc.nocontext\", split=\"validation\"\n",
    "# )\n",
    "# res_tqa_dict_len = len(tqa_dict)\n",
    "# print(f\"{res_tqa_dict_len = }\")\n",
    "\n",
    "# model_names = [\"llama\", \"mistral\", \"qwen\"]\n",
    "# # \"qwen\",\n",
    "\n",
    "# for mn in model_names:\n",
    "#     saved_file_name = f\"data/tqa_test_ds_{mn}.json\"\n",
    "\n",
    "#     save_data_dict(tqa_dict, saved_file_name)\n",
    "\n",
    "#     # Later, load the saved dictionary\n",
    "#     loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "#     print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TriviaQA Small Sample for test\n",
    "# tqa_dict = initialize_data_dict(\n",
    "#     process_triviaqa_sample, \"trivia_qa\", \"rc.nocontext\", split=\"validation\"\n",
    "# )\n",
    "# res_tqa_dict_len = len(tqa_dict)\n",
    "# print(f\"{res_tqa_dict_len = }\")\n",
    "\n",
    "# saved_file_name = f\"data/small_test_samples.json\"\n",
    "\n",
    "# save_data_dict(dict(list(tqa_dict.items())[:20]), saved_file_name)\n",
    "# # Later, load the saved dictionary\n",
    "# loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "# print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TriviaQA 500 Samples Usage\n",
    "# tqa_dict = initialize_data_dict(\n",
    "#     process_triviaqa_sample, \"trivia_qa\", \"rc.nocontext\", split=\"train\"\n",
    "# )\n",
    "# print(len(tqa_dict))\n",
    "\n",
    "# model_names = [\"qwen\",\"llama\",\"mistral\"]\n",
    "\n",
    "# for mn in model_names:\n",
    "#     saved_file_name = f\"data/tqa_train_ds_n1_{mn}.json\"\n",
    "\n",
    "#     save_data_dict(dict(list(tqa_dict.items())[2000:4000]), saved_file_name)\n",
    "\n",
    "#     # Later, load the saved dictionary\n",
    "#     loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "#     print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARC Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ARC Usage\n",
    "# arc_data_dict = initialize_data_dict(\n",
    "#     process_arc_sample, \"allenai/ai2_arc\", \"ARC-Challenge\", split=\"train\"\n",
    "# )\n",
    "# print(len(arc_data_dict))\n",
    "\n",
    "# # model_names = [\"qwen\",\"llama\",\"mistral\"]\n",
    "# model_names = [\"1\",\"3\",\"14\",\"32\"]\n",
    "# for mn in model_names:\n",
    "#     saved_file_name = f\"scaling_results/data/arc_train_ds_{mn}.json\"\n",
    "\n",
    "#     save_data_dict(dict(list(arc_data_dict.items())), saved_file_name)\n",
    "\n",
    "#     # Later, load the saved dictionary\n",
    "#     loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "#     print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ARC Usage\n",
    "# arc_data_dict = initialize_data_dict(\n",
    "#     process_arc_sample, \"allenai/ai2_arc\", \"ARC-Challenge\", split=\"test\"\n",
    "# )\n",
    "# print(len(arc_data_dict))\n",
    "\n",
    "# model_names = [\"qwen\",\"llama\",\"mistral\"]\n",
    "# model_names = [\"0\",\"1\",\"3\",\"14\",\"32\"]\n",
    "# # model_names = [\"1\"]\n",
    "# for mn in model_names:\n",
    "#     saved_file_name = f\"scaling_results/data/arc_test_ds_{mn}.json\"\n",
    "\n",
    "#     save_data_dict(dict(list(arc_data_dict.items())), saved_file_name)\n",
    "\n",
    "#     # Later, load the saved dictionary\n",
    "#     loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "#     print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CommonsenseQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CommonSenseQA Usage\n",
    "# arc_data_dict = initialize_data_dict(\n",
    "#     process_arc_sample, \"tau/commonsense_qa\", split=\"train\"\n",
    "# )\n",
    "# print(len(arc_data_dict))\n",
    "\n",
    "# model_names = [\"qwen\",\"llama\",\"mistral\"]\n",
    "\n",
    "# for mn in model_names:\n",
    "#     saved_file_name = f\"data/csqa_train_ds_n1_{mn}.json\"\n",
    "\n",
    "#     save_data_dict(dict(list(arc_data_dict.items())[2000:4000]), saved_file_name)\n",
    "#     # Later, load the saved dictionary\n",
    "#     loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "#     print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CommonSenseQA Usage\n",
    "# arc_data_dict = initialize_data_dict(\n",
    "#     process_arc_sample, \"tau/commonsense_qa\", split=\"validation\"\n",
    "# )\n",
    "# print(len(arc_data_dict))\n",
    "\n",
    "# model_names = [\"qwen\",\"llama\",\"mistral\"]\n",
    "\n",
    "# for mn in model_names:\n",
    "#     saved_file_name = f\"data/calibrated_baseline/csqa_test_ds_{mn}.json\"\n",
    "\n",
    "#     save_data_dict(dict(list(arc_data_dict.items())), saved_file_name)\n",
    "\n",
    "#     # Later, load the saved dictionary\n",
    "#     loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "#     print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CommonSenseQA Usage\n",
    "# arc_data_dict = initialize_data_dict(\n",
    "#     process_arc_sample, \"tau/commonsense_qa\", split=\"validation\"\n",
    "# )\n",
    "# print(len(arc_data_dict))\n",
    "\n",
    "# saved_file_name = f\"data/small_sample_csqa_test_qwen.json\"\n",
    "\n",
    "# save_data_dict(dict(list(arc_data_dict.items())[:200]), saved_file_name)\n",
    "\n",
    "# # Later, load the saved dictionary\n",
    "# loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "# print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge train ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset Usage\n",
    "# arc_data_dict = initialize_data_dict(\n",
    "#     process_arc_sample, \"allenai/ai2_arc\", \"ARC-Challenge\", split=\"train\"\n",
    "# )\n",
    "# csqa_data_dict = initialize_data_dict(\n",
    "#     process_arc_sample, \"tau/commonsense_qa\", split=\"train\"\n",
    "# )\n",
    "\n",
    "# csqa_subset = dict(list(csqa_data_dict.items())[0:2000])\n",
    "\n",
    "# # print(len(arc_data_dict))\n",
    "# # print(len(csqa_data_dict))\n",
    "\n",
    "# merged_dict = arc_data_dict | csqa_subset\n",
    "\n",
    "# # model_names = [\"qwen\",\"llama\",\"mistral\"]\n",
    "# model_names = [\"0\", \"1\", \"3\", \"14\", \"32\"]\n",
    "# model_names = [\"14\", \"32\"]\n",
    "# for mn in model_names:\n",
    "#     saved_file_name = f\"scaling_results/data/merged_train_ds_{mn}.json\"\n",
    "\n",
    "#     save_data_dict(dict(list(merged_dict.items())), saved_file_name)\n",
    "\n",
    "#     # Later, load the saved dictionary\n",
    "#     loaded_qa_dict = load_data_dict(saved_file_name)\n",
    "#     print(len(loaded_qa_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Dict\n",
    "# from pathlib import Path\n",
    "# import random\n",
    "\n",
    "\n",
    "# def merge_and_save_dicts(file_paths: List[str], ds_spli_name, model_name) -> None:\n",
    "#     \"\"\"\n",
    "#     Merge multiple dictionary files and save the merged result.\n",
    "\n",
    "#     Args:\n",
    "#         file_paths: List of file paths containing dictionaries to merge\n",
    "\n",
    "#     The function will save the merged dictionary to a new file with a name\n",
    "#     derived from common elements in the input filenames.\n",
    "#     \"\"\"\n",
    "#     # Initialize empty dictionary to store merged results\n",
    "#     merged_dict: Dict[str, Dict] = {}\n",
    "\n",
    "#     # Load and merge all dictionaries\n",
    "#     for file_path in file_paths:\n",
    "#         current_dict = load_data_dict(file_path)\n",
    "#         random.seed = 567\n",
    "#         current_dict = dict(random.sample(current_dict.items(), 200))\n",
    "#         merged_dict.update(current_dict)\n",
    "\n",
    "#     # Find common name pattern in files to use as output filename\n",
    "#     # file_names = [Path(path).stem for path in file_paths]\n",
    "#     # common_name = find_common_name(file_names)\n",
    "#     output_path = f\"./data/{ds_spli_name}_{model_name}_merged.json\"\n",
    "\n",
    "#     # Save merged dictionary\n",
    "#     save_data_dict(merged_dict, output_path)\n",
    "#     print(f\"succesfully saved file at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mns = [\"llama\", \"mistral\", \"qwen\"]\n",
    "\n",
    "# # tdsn = [\n",
    "# #     \"./data/csqa_train_ds_\",\n",
    "# #     \"./data/arc_train_ds_\",\n",
    "# #     \"./data/tqa_train_ds_\",\n",
    "# #     \"./data/csqa_train_ds_n1_\",\n",
    "# #     \"./data/tqa_train_ds_n1_\"\n",
    "# # ]\n",
    "\n",
    "# # val_ds = [\n",
    "# #     \"./data/csqa_test_ds_\",\n",
    "# #     \"./data/arc_test_ds_\",\n",
    "# #     \"./data/tqa_test_ds_\",\n",
    "# # ]\n",
    "\n",
    "# for mn in mns:\n",
    "#     res_names = [f\"{cdn}{mn}.json\" for cdn in val_ds]\n",
    "#     merge_and_save_dicts(res_names, \"valid_ds\", mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td = load_data_dict(\"./data/valid_ds_llama_merged.json\")\n",
    "# print(len(td))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
